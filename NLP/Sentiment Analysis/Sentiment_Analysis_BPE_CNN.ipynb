{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment-Analysis--TF-idf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sentiment Analysis  \n",
        "The Model consists of two phases:\n",
        "#### Embedding Layer\n",
        "Pretrained embedding layer using byte-pair encoding; BPEmb toolkit is used.\n",
        "#### CNN\n",
        "Complex features from sentences are extracted using a convolutional neural network. Classification is done using a softmax layer directly after the CNN.  \n",
        "  \n",
        "The dataset is used from kaggle's Sentiment analysis challenge  \n",
        "https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "rhrpv53JIkz1",
        "outputId": "74de77f8-8da4-4efb-b6ff-d38b064c1a6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading sentiment-analysis-on-movie-reviews.zip to /content\n",
            "\r  0% 0.00/1.90M [00:00<?, ?B/s]\n",
            "\r100% 1.90M/1.90M [00:00<00:00, 126MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c sentiment-analysis-on-movie-reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "colab_type": "code",
        "id": "r6LL_oYuJBss",
        "outputId": "f6d83fd4-b514-4c3d-bbf9-080922b976c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  sentiment-analysis-on-movie-reviews.zip\n",
            "  inflating: sentiment-analysis-on-movie-reviews/sampleSubmission.csv  \n",
            "  inflating: sentiment-analysis-on-movie-reviews/test.tsv.zip  \n",
            "  inflating: sentiment-analysis-on-movie-reviews/train.tsv.zip  \n"
          ]
        }
      ],
      "source": [
        "!unzip sentiment-analysis-on-movie-reviews.zip -d sentiment-analysis-on-movie-reviews/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "QOM5iC4_JLRU",
        "outputId": "f63462ea-e045-4b82-d570-cfba984f51cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  sentiment-analysis-on-movie-reviews/train.tsv.zip\n",
            "  inflating: train.tsv               \n"
          ]
        }
      ],
      "source": [
        "!unzip sentiment-analysis-on-movie-reviews/train.tsv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "CXO-F8FrJWNU",
        "outputId": "295c2e5b-56ff-46ce-d2d0-660dbb3fb44c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  sentiment-analysis-on-movie-reviews/test.tsv.zip\n",
            "  inflating: test.tsv                \n"
          ]
        }
      ],
      "source": [
        "!unzip sentiment-analysis-on-movie-reviews/test.tsv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "colab_type": "code",
        "id": "Hqk3O_g0LN2n",
        "outputId": "e3098a64-c232-421b-c7b4-f0ce0045bf07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bpemb\n",
            "  Downloading bpemb-0.3.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb) (1.17.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from bpemb) (3.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bpemb) (4.28.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (3.0.4)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.9.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.4.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (1.11.15)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (2.49.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (1.14.15)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.2.1->gensim->bpemb) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.2.1->gensim->bpemb) (2.6.1)\n",
            "Installing collected packages: sentencepiece, bpemb\n",
            "Successfully installed bpemb-0.3.0 sentencepiece-0.1.85\n"
          ]
        }
      ],
      "source": [
        "!pip install bpemb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "colab_type": "code",
        "id": "rXuS5s7H__-g",
        "outputId": "011be53c-9b58-4cdd-b679-40289529ddf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0\n",
            "  Downloading tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8 MB 31 kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "  Downloading tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449 kB)\n",
            "\u001b[K     |████████████████████████████████| 449 kB 52.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.27.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.17.5)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.2.2)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "  Downloading tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 61.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0) (45.1.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu==2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "akC1nWUbIZSY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from bpemb import BPEmb\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "JNIJmeLMJav-"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
        "test_df = pd.read_csv(\"test.tsv\", sep=\"\\t\")\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "7TsfQpqRK4Ry",
        "outputId": "bf2f8ed1-6e3c-425b-c7e5-41e1de224349"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "SWhDyzWlLMdo",
        "outputId": "79943238-be92-42d9-cdcb-1b9a32422d7f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>156061</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>156062</td>\n",
              "      <td>8545</td>\n",
              "      <td>An intermittently pleasing but mostly routine ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>156063</td>\n",
              "      <td>8545</td>\n",
              "      <td>An</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>156064</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine effort</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>156065</td>\n",
              "      <td>8545</td>\n",
              "      <td>intermittently pleasing but mostly routine</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase\n",
              "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
              "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
              "2    156063        8545                                                 An\n",
              "3    156064        8545  intermittently pleasing but mostly routine effort\n",
              "4    156065        8545         intermittently pleasing but mostly routine"
            ]
          },
          "execution_count": 12,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "colab_type": "code",
        "id": "xTsdAioXQYoE",
        "outputId": "904576f0-6ac6-4dfc-a4ca-9081861b8f2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 400869/400869 [00:00<00:00, 564973.01B/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.d50.w2v.bin.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1924908/1924908 [00:01<00:00, 1885182.70B/s]\n",
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ]
        }
      ],
      "source": [
        "bpemb_en = BPEmb(lang=\"en\", dim=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "caiZfXgJTGR9",
        "outputId": "9fb76ad4-2276-4319-b432-f1c55fd11f25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "156060\n"
          ]
        }
      ],
      "source": [
        "phrases_list = train_df['Phrase'].to_list()\n",
        "print(len(phrases_list))\n",
        "labels_list = [int(l) for l in train_df['Sentiment'].to_list()]\n",
        "subword_list = [\" \".join(bpemb_en.encode(line)) for line in phrases_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "RfQ--lxLEQLT"
      },
      "outputs": [],
      "source": [
        "def caster(example, label):\n",
        "  return example, tf.cast(int(label), tf.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a dictionary to encode subwords that is integratable with tensorflow graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aSpNFERVKZpE"
      },
      "outputs": [],
      "source": [
        "encoder = tf.lookup.StaticVocabularyTable(\n",
        "    tf.lookup.KeyValueTensorInitializer(bpemb_en.words, tf.cast(range(len(bpemb_en.words)), tf.int64)), 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DZSBLdnWDl-D"
      },
      "outputs": [],
      "source": [
        "lines_dataset = tf.data.Dataset.from_tensor_slices(subword_list)\n",
        "labels_dataset = tf.data.Dataset.from_tensor_slices(labels_list)\n",
        "lines_labels_ds = tf.data.Dataset.zip((lines_dataset, labels_dataset))\n",
        "lines_labels_ds = lines_labels_ds.map(lambda ex, label: caster(ex, label))\n",
        "lines_labels_ds = lines_labels_ds.shuffle(200000)\n",
        "ids_labels_ds = lines_labels_ds.map(lambda a, b: (encoder.lookup(tf.strings.split(a)), b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_UlWKQJGPYOh"
      },
      "outputs": [],
      "source": [
        "bpe_tensor = tf.convert_to_tensor(bpemb_en.vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fKF3sBo-sczf"
      },
      "outputs": [],
      "source": [
        "class PretrainedEmbedding(tf.keras.layers.Layer):\n",
        "    \"\"\"Non-trainable embedding layer.\"\"\"\n",
        "\n",
        "    def __init__(self, embeddings, rate=0.1, **kwargs):\n",
        "        \"\"\"\"Instantiate the layer using a pre-defined embedding matrix.\"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.embeddings = tf.constant(embeddings)\n",
        "        # if you want to add some dropout (or normalization, etc.)\n",
        "        self.dropout = tf.keras.layers.Dropout(rate=rate)\n",
        "\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"Embed some input tokens and optionally apply dropout.\"\"\"\n",
        "\n",
        "        output = tf.nn.embedding_lookup(self.embeddings, inputs)\n",
        "        return self.dropout(output, training=training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Mr47Pjh3GWxE"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, width, growth_rate, name):\n",
        "\n",
        "  x1 = layers.BatchNormalization(epsilon=1.001e-5,\n",
        "                                  name=name + '_0_bn')(x)\n",
        "  x1 = layers.ReLU(max_value=6., name=name + '_0_relu')(x1)\n",
        "  x1 = layers.Dropout(0.2)(x1)\n",
        "  x1 = layers.Conv2D(4 * growth_rate, (1, width),\n",
        "                      use_bias=False,\n",
        "                      name=name + '_1_conv')(x1)\n",
        "  x1 = tf.squeeze(x1, axis=-2)\n",
        "  x1 = tf.expand_dims(x1, -1)\n",
        "\n",
        "  x1 = layers.BatchNormalization(epsilon=1.001e-5,\n",
        "                                  name=name + '_1_bn')(x1)\n",
        "  x1 = layers.ReLU(max_value=6., name=name + '_1_relu')(x1)\n",
        "  x1 = layers.Dropout(0.2)(x1)\n",
        "\n",
        "  x2 = tf.pad(x1, [[0,0],[1,1],[0,0],[0,0]])\n",
        "  x2 = layers.Conv2D(growth_rate, (3, 4 * growth_rate),\n",
        "                      use_bias=False,\n",
        "                      name=name + '_2_conv')(x2)\n",
        "  x2 = tf.squeeze(x2, axis=-2)\n",
        "  x2 = tf.expand_dims(x2, -1)\n",
        "\n",
        "  x3 = tf.pad(x1, [[0,0],[2,2],[0,0],[0,0]])\n",
        "  x3 = layers.Conv2D(growth_rate, (5, 4 * growth_rate),\n",
        "                      use_bias=False,\n",
        "                      name=name + '_3_conv')(x3)\n",
        "  x3 = tf.squeeze(x3, axis=-2)\n",
        "  x3 = tf.expand_dims(x3, -1)\n",
        "\n",
        "  x = layers.Concatenate(name=name + '_concat', axis=-2)([x, x2, x3])\n",
        "  return x\n",
        "\n",
        "def dense_block(x, inp_depth, blocks, name, growth=64):\n",
        "\n",
        "  width = inp_depth\n",
        "  for i in range(blocks):\n",
        "      x = conv_block(x, width, growth, name=name + '_block' + str(i + 1))\n",
        "      width = growth * 2 + width\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "oWt91tYgHsyU",
        "outputId": "34c74452-d726-4c43-bbcd-1e05a3cb2855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_17 (InputLayer)           [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "pretrained_embedding_16 (Pretra (None, None, 50)     0           input_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_316 (Ten [(None, None, 50, 1) 0           pretrained_embedding_16[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, 1, 32)  1600        tf_op_layer_ExpandDims_316[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_301 (Tensor [(None, None, 32)]   0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_317 (Ten [(None, None, 32, 1) 0           tf_op_layer_Squeeze_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block1_0_bn (BatchNorma (None, None, 32, 1)  4           tf_op_layer_ExpandDims_317[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block1_0_relu (ReLU)    (None, None, 32, 1)  0           dense_1_block1_0_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_228 (Dropout)           (None, None, 32, 1)  0           dense_1_block1_0_relu[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block1_1_conv (Conv2D)  (None, None, 1, 48)  1536        dropout_228[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_302 (Tensor [(None, None, 48)]   0           dense_1_block1_1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_318 (Ten [(None, None, 48, 1) 0           tf_op_layer_Squeeze_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block1_1_bn (BatchNorma (None, None, 48, 1)  4           tf_op_layer_ExpandDims_318[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block1_1_relu (ReLU)    (None, None, 48, 1)  0           dense_1_block1_1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_229 (Dropout)           (None, None, 48, 1)  0           dense_1_block1_1_relu[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Pad_170 (TensorFlow [(None, None, 48, 1) 0           dropout_229[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Pad_171 (TensorFlow [(None, None, 48, 1) 0           dropout_229[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block1_2_conv (Conv2D)  (None, None, 1, 12)  1728        tf_op_layer_Pad_170[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block1_3_conv (Conv2D)  (None, None, 1, 12)  2880        tf_op_layer_Pad_171[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_303 (Tensor [(None, None, 12)]   0           dense_1_block1_2_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_304 (Tensor [(None, None, 12)]   0           dense_1_block1_3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_319 (Ten [(None, None, 12, 1) 0           tf_op_layer_Squeeze_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_320 (Ten [(None, None, 12, 1) 0           tf_op_layer_Squeeze_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block1_concat (Concaten (None, None, 56, 1)  0           tf_op_layer_ExpandDims_317[0][0] \n",
            "                                                                 tf_op_layer_ExpandDims_319[0][0] \n",
            "                                                                 tf_op_layer_ExpandDims_320[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block2_0_bn (BatchNorma (None, None, 56, 1)  4           dense_1_block1_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block2_0_relu (ReLU)    (None, None, 56, 1)  0           dense_1_block2_0_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_230 (Dropout)           (None, None, 56, 1)  0           dense_1_block2_0_relu[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block2_1_conv (Conv2D)  (None, None, 1, 48)  2688        dropout_230[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_305 (Tensor [(None, None, 48)]   0           dense_1_block2_1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_321 (Ten [(None, None, 48, 1) 0           tf_op_layer_Squeeze_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block2_1_bn (BatchNorma (None, None, 48, 1)  4           tf_op_layer_ExpandDims_321[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block2_1_relu (ReLU)    (None, None, 48, 1)  0           dense_1_block2_1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_231 (Dropout)           (None, None, 48, 1)  0           dense_1_block2_1_relu[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Pad_172 (TensorFlow [(None, None, 48, 1) 0           dropout_231[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Pad_173 (TensorFlow [(None, None, 48, 1) 0           dropout_231[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block2_2_conv (Conv2D)  (None, None, 1, 12)  1728        tf_op_layer_Pad_172[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block2_3_conv (Conv2D)  (None, None, 1, 12)  2880        tf_op_layer_Pad_173[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_306 (Tensor [(None, None, 12)]   0           dense_1_block2_2_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_307 (Tensor [(None, None, 12)]   0           dense_1_block2_3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_322 (Ten [(None, None, 12, 1) 0           tf_op_layer_Squeeze_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_323 (Ten [(None, None, 12, 1) 0           tf_op_layer_Squeeze_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block2_concat (Concaten (None, None, 80, 1)  0           dense_1_block1_concat[0][0]      \n",
            "                                                                 tf_op_layer_ExpandDims_322[0][0] \n",
            "                                                                 tf_op_layer_ExpandDims_323[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block3_0_bn (BatchNorma (None, None, 80, 1)  4           dense_1_block2_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block3_0_relu (ReLU)    (None, None, 80, 1)  0           dense_1_block3_0_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_232 (Dropout)           (None, None, 80, 1)  0           dense_1_block3_0_relu[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block3_1_conv (Conv2D)  (None, None, 1, 48)  3840        dropout_232[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_308 (Tensor [(None, None, 48)]   0           dense_1_block3_1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_324 (Ten [(None, None, 48, 1) 0           tf_op_layer_Squeeze_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block3_1_bn (BatchNorma (None, None, 48, 1)  4           tf_op_layer_ExpandDims_324[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block3_1_relu (ReLU)    (None, None, 48, 1)  0           dense_1_block3_1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_233 (Dropout)           (None, None, 48, 1)  0           dense_1_block3_1_relu[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Pad_174 (TensorFlow [(None, None, 48, 1) 0           dropout_233[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Pad_175 (TensorFlow [(None, None, 48, 1) 0           dropout_233[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block3_2_conv (Conv2D)  (None, None, 1, 12)  1728        tf_op_layer_Pad_174[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block3_3_conv (Conv2D)  (None, None, 1, 12)  2880        tf_op_layer_Pad_175[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_309 (Tensor [(None, None, 12)]   0           dense_1_block3_2_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_310 (Tensor [(None, None, 12)]   0           dense_1_block3_3_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_325 (Ten [(None, None, 12, 1) 0           tf_op_layer_Squeeze_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_326 (Ten [(None, None, 12, 1) 0           tf_op_layer_Squeeze_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_block3_concat (Concaten (None, None, 104, 1) 0           dense_1_block2_concat[0][0]      \n",
            "                                                                 tf_op_layer_ExpandDims_325[0][0] \n",
            "                                                                 tf_op_layer_ExpandDims_326[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, 104, 1) 4           dense_1_block3_concat[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_22 (ReLU)                 (None, None, 104, 1) 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_234 (Dropout)           (None, None, 104, 1) 0           re_lu_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_311 (Tensor [(None, None, 104)]  0           dropout_234[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_327 (Ten [(None, None, 1, 104 0           tf_op_layer_Squeeze_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_13 (Global (None, 104)          0           tf_op_layer_ExpandDims_327[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 6)            630         global_max_pooling2d_13[0][0]    \n",
            "==================================================================================================\n",
            "Total params: 24,146\n",
            "Trainable params: 24,132\n",
            "Non-trainable params: 14\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.layers.Input(shape=(None,), dtype=tf.int64)\n",
        "\n",
        "x = PretrainedEmbedding(tf.pad(bpe_tensor, [[0, 3], [0, 0]]))(inputs)\n",
        "x = tf.expand_dims(x, -1)\n",
        "x = layers.Conv2D(32, (1, 50),\n",
        "                    use_bias=False)(x)\n",
        "x = tf.squeeze(x, axis=-2)\n",
        "x = tf.expand_dims(x, -1)\n",
        "\n",
        "x = dense_block(x, 32, 3, \"dense_1\", 12)\n",
        "x = layers.BatchNormalization(epsilon=1.001e-5)(x)\n",
        "x = layers.ReLU(max_value=6.)(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "# x = layers.Conv2D(64, (1, 80), use_bias=False)(x)\n",
        "# x = tf.squeeze(x, axis=-2)\n",
        "# x = tf.expand_dims(x, -1)\n",
        "\n",
        "# x = dense_block(x, 64, 2, \"dense_2\", 12)\n",
        "# x = keras.layers.BatchNormalization()(x)\n",
        "# x = keras.layers.ReLU(6.)(x)\n",
        "# x = layers.Dropout(0.2)(x)\n",
        "\n",
        "# x = layers.Conv2D(96, (1, 224), use_bias=False)(x)\n",
        "# x = tf.squeeze(x, axis=-2)\n",
        "# x = tf.expand_dims(x, -1)\n",
        "\n",
        "# x = dense_block(x, 96, 5, \"dense_3\", 32)\n",
        "# x = keras.layers.BatchNormalization()(x)\n",
        "# x = keras.layers.ReLU(6.)(x)\n",
        "# x = layers.Dropout(0.2)(x)\n",
        "\n",
        "x = tf.squeeze(x, axis=-1)\n",
        "x = tf.expand_dims(x, -2)\n",
        "x = keras.layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "x = keras.layers.Dense(6, activation='softmax')(x)\n",
        "\n",
        "model = keras.models.Model(inputs, x)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2tncB91IrL6Y"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 96\n",
        "steps_per_epoch = 156060*0.8 // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MYfZdQ9QrivJ"
      },
      "outputs": [],
      "source": [
        "ids_one_hot_ds = ids_labels_ds.map(lambda a, b: (a, tf.one_hot(tf.cast(b, tf.int32), 6)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "po3N6cguSLnN"
      },
      "outputs": [],
      "source": [
        "ds = ids_one_hot_ds.padded_batch(BATCH_SIZE, padded_shapes=((None,), [6]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "nZfU_kVTUkyr",
        "outputId": "6059c3f8-6191-4ad1-99df-7aa23a2a6572"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[96 51] [96 6]\n"
          ]
        }
      ],
      "source": [
        "for a, b in ds.take(1):\n",
        "  tf.print(tf.shape(a), tf.shape(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PfjI7n8AWVi8"
      },
      "outputs": [],
      "source": [
        "train_batches = int(156060 * 0.8 // BATCH_SIZE)\n",
        "valid_batches = int(156060 // BATCH_SIZE) - train_batches\n",
        "train_ds = ds.take(train_batches).repeat()\n",
        "valid_ds = ds.skip(train_batches).repeat()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "11OY16oRkjN3"
      },
      "outputs": [],
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=train_batches*3,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "colab_type": "code",
        "id": "qzBpc9B7qJ1K",
        "outputId": "2f9f37d0-9c99-4384-cf1e-611a2b1e8017"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20/20 [==============================] - 7s 357ms/step - loss: 1.5821 - accuracy: 0.2990\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.5820520162582397, 0.29895833]"
            ]
          },
          "execution_count": 104,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(train_ds, steps=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "colab_type": "code",
        "id": "Ev4hdUm1r5Rz",
        "outputId": "f0a2e976-f5ca-46c0-e8dc-1163db6a3e96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train for 1300 steps, validate for 325 steps\n",
            "Epoch 1/100\n",
            "1300/1300 [==============================] - 384s 295ms/step - loss: 1.1165 - accuracy: 0.5449 - val_loss: 1.1431 - val_accuracy: 0.5494\n",
            "Epoch 2/100\n",
            "1300/1300 [==============================] - 387s 297ms/step - loss: 1.0773 - accuracy: 0.5564 - val_loss: 1.0952 - val_accuracy: 0.5712\n",
            "Epoch 3/100\n",
            "1300/1300 [==============================] - 385s 296ms/step - loss: 1.0613 - accuracy: 0.5632 - val_loss: 1.0763 - val_accuracy: 0.5797\n",
            "Epoch 4/100\n",
            "1300/1300 [==============================] - 388s 299ms/step - loss: 1.0495 - accuracy: 0.5682 - val_loss: 1.0786 - val_accuracy: 0.5715\n",
            "Epoch 5/100\n",
            "1300/1300 [==============================] - 383s 295ms/step - loss: 1.0398 - accuracy: 0.5720 - val_loss: 1.0354 - val_accuracy: 0.5938\n",
            "Epoch 6/100\n",
            "1300/1300 [==============================] - 389s 299ms/step - loss: 1.0343 - accuracy: 0.5736 - val_loss: 1.0622 - val_accuracy: 0.5743\n",
            "Epoch 7/100\n",
            "1300/1300 [==============================] - 390s 300ms/step - loss: 1.0259 - accuracy: 0.5778 - val_loss: 1.0378 - val_accuracy: 0.5924\n",
            "Epoch 8/100\n",
            "1300/1300 [==============================] - 392s 301ms/step - loss: 1.0239 - accuracy: 0.5785 - val_loss: 1.0488 - val_accuracy: 0.5871\n",
            "Epoch 9/100\n",
            "1300/1300 [==============================] - 388s 299ms/step - loss: 1.0196 - accuracy: 0.5800 - val_loss: 1.0436 - val_accuracy: 0.5931\n",
            "Epoch 10/100\n",
            " 418/1300 [========>.....................] - ETA: 4:03 - loss: 1.0212 - accuracy: 0.5792"
          ]
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=7, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    callbacks=[callback],\n",
        "                    steps_per_epoch=train_batches,\n",
        "                    epochs=100,\n",
        "                    validation_data=valid_ds,\n",
        "                    validation_steps=valid_batches)\n",
        "model.save(\"./drive/My Drive/Models/bpe_cnn_sentiment_dense_25k\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "KrQPGPH-BV-u",
        "outputId": "59c24eda-6cae-4c73-88ae-b0e4eacce2e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5.71481764e-01, 3.49923372e-01, 6.03016578e-02, 1.50448903e-02,\n",
              "        3.24834231e-03, 1.82212845e-09],\n",
              "       [4.34644185e-02, 2.61657894e-01, 4.84695137e-01, 1.84816062e-01,\n",
              "        2.53661871e-02, 2.94708030e-07],\n",
              "       [2.28226017e-02, 2.08390594e-01, 6.27331972e-01, 1.30020961e-01,\n",
              "        1.14337737e-02, 6.14191293e-08],\n",
              "       [1.15798097e-02, 4.53853607e-02, 1.01600423e-01, 5.16200960e-01,\n",
              "        3.25233519e-01, 1.03121742e-08],\n",
              "       [1.39030023e-02, 1.28053069e-01, 7.41781831e-01, 1.06276020e-01,\n",
              "        9.98499244e-03, 1.13110684e-06],\n",
              "       [6.25831401e-03, 9.43449736e-02, 7.07537949e-01, 1.77843809e-01,\n",
              "        1.40145561e-02, 4.22808938e-07],\n",
              "       [1.79886833e-01, 3.89868408e-01, 1.41829178e-01, 2.31314451e-01,\n",
              "        5.71011640e-02, 4.72720663e-09],\n",
              "       [3.41352122e-03, 2.74295788e-02, 1.69493884e-01, 4.84207720e-01,\n",
              "        3.15455347e-01, 5.69518050e-08],\n",
              "       [1.26760276e-02, 1.32148415e-01, 6.39648676e-01, 1.90029860e-01,\n",
              "        2.54964549e-02, 4.66407670e-07],\n",
              "       [1.48476614e-02, 1.99173376e-01, 7.08328485e-01, 7.35120922e-02,\n",
              "        4.13706666e-03, 1.27033525e-06],\n",
              "       [1.90332364e-02, 1.38568848e-01, 5.06304562e-01, 2.96308130e-01,\n",
              "        3.97846960e-02, 5.56036923e-07],\n",
              "       [4.51117568e-03, 7.28579685e-02, 7.82752395e-01, 1.28665403e-01,\n",
              "        1.12126237e-02, 3.91361368e-07],\n",
              "       [5.26667014e-03, 9.70191956e-02, 7.11264670e-01, 1.81348681e-01,\n",
              "        5.10078715e-03, 7.65825359e-09],\n",
              "       [5.00487648e-02, 3.65963101e-01, 4.31275159e-01, 1.37078583e-01,\n",
              "        1.56340357e-02, 3.00214936e-07],\n",
              "       [2.25037267e-03, 3.82321179e-02, 7.65986383e-01, 1.75336167e-01,\n",
              "        1.81944128e-02, 5.20128253e-07],\n",
              "       [8.20316598e-02, 3.52980763e-01, 3.55344832e-01, 1.82439253e-01,\n",
              "        2.72034705e-02, 6.58514523e-08],\n",
              "       [2.14240365e-02, 1.61500931e-01, 5.43170214e-01, 2.38907278e-01,\n",
              "        3.49974446e-02, 1.60837558e-07],\n",
              "       [5.87708242e-02, 2.94560045e-01, 2.04019383e-01, 3.75796139e-01,\n",
              "        6.68535307e-02, 5.66464884e-08],\n",
              "       [4.72971704e-03, 5.53302988e-02, 6.93458080e-01, 2.20814303e-01,\n",
              "        2.56673247e-02, 2.82172294e-07],\n",
              "       [1.63853392e-02, 9.87782702e-02, 3.93577367e-01, 3.52418214e-01,\n",
              "        1.38840675e-01, 5.39679590e-08],\n",
              "       [1.37618139e-01, 4.98547196e-01, 3.20234984e-01, 4.01564874e-02,\n",
              "        3.44299641e-03, 6.15883877e-08],\n",
              "       [4.18352289e-03, 7.70655200e-02, 7.94687092e-01, 1.18849650e-01,\n",
              "        5.21323830e-03, 9.11882410e-07],\n",
              "       [1.29439812e-02, 1.59555018e-01, 7.50023782e-01, 7.22738653e-02,\n",
              "        5.20312414e-03, 2.71008702e-07],\n",
              "       [1.36271981e-03, 1.04526002e-02, 8.50957409e-02, 5.40339231e-01,\n",
              "        3.62749666e-01, 2.59012367e-09],\n",
              "       [8.26937333e-02, 3.66430789e-01, 3.22405905e-01, 1.79315418e-01,\n",
              "        4.91540432e-02, 5.41149632e-08],\n",
              "       [1.81505278e-01, 5.09181440e-01, 1.60908550e-01, 1.26291946e-01,\n",
              "        2.21127924e-02, 1.24317245e-09],\n",
              "       [1.34010171e-03, 1.13116251e-02, 3.41814235e-02, 5.19797742e-01,\n",
              "        4.33369100e-01, 7.44013562e-09],\n",
              "       [1.23592559e-02, 1.55256420e-01, 5.98606050e-01, 2.11105838e-01,\n",
              "        2.26722118e-02, 3.02712522e-07],\n",
              "       [1.99029082e-03, 3.48995328e-02, 8.68868291e-01, 8.91844407e-02,\n",
              "        5.05587179e-03, 1.50437381e-06],\n",
              "       [5.93857560e-03, 7.91103616e-02, 8.39157164e-01, 7.03831315e-02,\n",
              "        5.40887564e-03, 1.75780576e-06],\n",
              "       [2.87926872e-03, 4.72562276e-02, 8.39305460e-01, 1.03115179e-01,\n",
              "        7.44366320e-03, 3.19819719e-07],\n",
              "       [7.57854944e-03, 1.03988744e-01, 7.91592598e-01, 8.86201784e-02,\n",
              "        8.21914151e-03, 8.23484754e-07],\n",
              "       [4.83551063e-02, 2.74807006e-01, 4.30818975e-01, 2.11537629e-01,\n",
              "        3.44812497e-02, 7.60586332e-08],\n",
              "       [7.17088906e-03, 3.46394815e-02, 7.62673542e-02, 5.08133233e-01,\n",
              "        3.73788893e-01, 1.81440342e-07],\n",
              "       [2.13171216e-03, 2.97686066e-02, 6.35084510e-01, 2.79487848e-01,\n",
              "        5.35269156e-02, 4.86711883e-07],\n",
              "       [1.26809219e-03, 2.75421478e-02, 8.77840877e-01, 8.84257704e-02,\n",
              "        4.92263958e-03, 3.90063605e-07],\n",
              "       [8.31325538e-04, 2.86942329e-02, 8.56205642e-01, 1.09817170e-01,\n",
              "        4.45144158e-03, 2.12427736e-07],\n",
              "       [7.08969776e-03, 7.82734230e-02, 3.00069243e-01, 5.18302262e-01,\n",
              "        9.62647349e-02, 5.57343981e-07],\n",
              "       [3.66814062e-02, 3.18793476e-01, 3.34914595e-01, 2.66542584e-01,\n",
              "        4.30679210e-02, 4.49778703e-08],\n",
              "       [6.00053789e-03, 6.96625337e-02, 2.82632560e-01, 5.15196979e-01,\n",
              "        1.26507372e-01, 1.12529763e-08],\n",
              "       [1.68675985e-02, 6.64586797e-02, 4.41242680e-02, 4.12634373e-01,\n",
              "        4.59915131e-01, 1.93091335e-10],\n",
              "       [7.52947181e-02, 3.33858371e-01, 3.23560923e-01, 2.15897754e-01,\n",
              "        5.13882637e-02, 1.69208985e-08],\n",
              "       [4.20737593e-03, 6.60088882e-02, 8.63531470e-01, 6.31147996e-02,\n",
              "        3.13692493e-03, 6.07234199e-07],\n",
              "       [1.14573613e-02, 1.22806743e-01, 5.83205283e-01, 2.58748680e-01,\n",
              "        2.37818398e-02, 1.39073236e-07],\n",
              "       [4.05139960e-02, 1.83961853e-01, 2.94237256e-01, 3.98503542e-01,\n",
              "        8.27831030e-02, 2.98931326e-07],\n",
              "       [4.72205542e-02, 2.36294240e-01, 3.54604840e-01, 3.30987453e-01,\n",
              "        3.08929086e-02, 1.03891491e-08],\n",
              "       [1.05905663e-02, 1.33474931e-01, 5.97950041e-01, 2.26116136e-01,\n",
              "        3.18673849e-02, 9.60295324e-07],\n",
              "       [9.66206491e-02, 4.26470309e-01, 2.93666065e-01, 1.57576740e-01,\n",
              "        2.56660711e-02, 1.02261041e-07],\n",
              "       [1.46982800e-02, 1.19701624e-01, 3.46095771e-01, 4.30570811e-01,\n",
              "        8.89334828e-02, 1.63161236e-08],\n",
              "       [2.33733244e-02, 1.99858055e-01, 6.19958580e-01, 1.46567151e-01,\n",
              "        1.02428365e-02, 5.71035841e-08],\n",
              "       [1.77867971e-02, 7.31727630e-02, 1.86935261e-01, 4.83782619e-01,\n",
              "        2.38322556e-01, 1.32703821e-08],\n",
              "       [9.06060636e-03, 1.01132683e-01, 4.31307614e-01, 4.12288368e-01,\n",
              "        4.62099537e-02, 8.66738617e-07],\n",
              "       [2.31301319e-03, 5.47155067e-02, 8.09238791e-01, 1.24352761e-01,\n",
              "        9.37981158e-03, 1.26875548e-07],\n",
              "       [2.09609303e-03, 4.41916324e-02, 8.34724247e-01, 1.11549146e-01,\n",
              "        7.43842870e-03, 4.57452984e-07],\n",
              "       [6.87100459e-03, 1.04071788e-01, 8.39808345e-01, 4.72921357e-02,\n",
              "        1.95551524e-03, 1.15465048e-06],\n",
              "       [1.00121312e-02, 8.88130292e-02, 7.12903917e-01, 1.62844822e-01,\n",
              "        2.54255887e-02, 5.39835014e-07],\n",
              "       [7.68803880e-02, 4.67589766e-01, 3.48011017e-01, 9.85400528e-02,\n",
              "        8.97851866e-03, 1.67832312e-07],\n",
              "       [1.53073398e-02, 1.32312968e-01, 5.29782891e-01, 2.85524637e-01,\n",
              "        3.70721892e-02, 2.28444303e-08],\n",
              "       [2.79034092e-03, 5.59472628e-02, 6.90953672e-01, 2.31529370e-01,\n",
              "        1.87783688e-02, 9.47247543e-07],\n",
              "       [2.04641204e-02, 1.60636112e-01, 6.51013672e-01, 1.55207038e-01,\n",
              "        1.26783550e-02, 7.44590579e-07],\n",
              "       [6.94155134e-03, 9.86820236e-02, 7.76435196e-01, 1.06935844e-01,\n",
              "        1.10044293e-02, 1.03458387e-06],\n",
              "       [1.63505003e-01, 4.00446177e-01, 1.99489459e-01, 2.01254040e-01,\n",
              "        3.53053771e-02, 5.02466424e-09],\n",
              "       [6.46414096e-03, 8.08001459e-02, 7.42197454e-01, 1.53989151e-01,\n",
              "        1.65458750e-02, 3.29609338e-06],\n",
              "       [3.89492535e-03, 1.77816711e-02, 5.23646362e-02, 3.56238604e-01,\n",
              "        5.69720149e-01, 2.49502179e-08]], dtype=float32)"
            ]
          },
          "execution_count": 80,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(next(iter(valid_ds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "vMrXOIZ0L8fe"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}