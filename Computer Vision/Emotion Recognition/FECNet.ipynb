{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FECNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Facial Expression Comparison (in progress)\n",
        "\n",
        "Implementation of the paper: http://openaccess.thecvf.com/content_CVPR_2019/html/Vemulapalli_A_Compact_Embedding_for_Facial_Expression_Similarity_CVPR_2019_paper.html  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "colab_type": "code",
        "id": "_G0hrsaBCKjw",
        "outputId": "44c23465-1d46-4bee-99b9-393c49113794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.12.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.34.2)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.17.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.2.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.11.2)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.27.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0) (1.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.2.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.7.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (45.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (2.21.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0) (2.8.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "Successfully installed tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu==2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "colab_type": "code",
        "id": "ZfQ8qO65ol0f",
        "outputId": "52ea5e68-59c4-43a9-9f58-6a260c28be13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7c4EvDifMW1d"
      },
      "outputs": [],
      "source": [
        "!tar -xf \"./drive/My Drive/Datasets/fer_4_classes.tar.xz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "BIL6ZS1lCT8r",
        "outputId": "1a94a907-9e66-43c4-be17-bb5e8f98197f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KEmsP4l9GJYX"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
        "from tensorflow.keras.layers import Layer\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pandas as pd\n",
        "import tensorflow.keras as K\n",
        "\n",
        "def LRN2D(x):\n",
        "  return tf.nn.lrn(x, alpha=1e-4, beta=0.75)\n",
        "\n",
        "def conv2d_bn(\n",
        "  x,\n",
        "  layer=None,\n",
        "  cv1_out=None,\n",
        "  cv1_filter=(1, 1),\n",
        "  cv1_strides=(1, 1),\n",
        "  cv2_out=None,\n",
        "  cv2_filter=(3, 3),\n",
        "  cv2_strides=(1, 1),\n",
        "  padding=None,\n",
        "):\n",
        "  num = '' if cv2_out == None else '1'\n",
        "  tensor = Conv2D(cv1_out, cv1_filter, strides=cv1_strides, name=layer+'_conv'+num)(x)\n",
        "  tensor = BatchNormalization(axis=3, epsilon=0.00001, name=layer+'_bn'+num)(tensor)\n",
        "  tensor = Activation('relu')(tensor)\n",
        "  if padding == None:\n",
        "    return tensor\n",
        "  tensor = ZeroPadding2D(padding=padding)(tensor)\n",
        "  if cv2_out == None:\n",
        "    return tensor\n",
        "  tensor = Conv2D(cv2_out, cv2_filter, strides=cv2_strides, name=layer+'_conv'+'2')(tensor)\n",
        "  tensor = BatchNormalization(axis=3, epsilon=0.00001, name=layer+'_bn'+'2')(tensor)\n",
        "  tensor = Activation('relu')(tensor)\n",
        "  return tensor\n",
        "\n",
        "def facenet():\n",
        "    myInput = Input(shape=(96, 96, 3))\n",
        "\n",
        "    x = ZeroPadding2D(padding=(3, 3), input_shape=(96, 96, 3))(myInput)\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
        "    x = BatchNormalization(axis=3, epsilon=0.00001, name='bn1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
        "    x = Lambda(LRN2D, name='lrn_1')(x)\n",
        "    x = Conv2D(64, (1, 1), name='conv2')(x)\n",
        "    x = BatchNormalization(axis=3, epsilon=0.00001, name='bn2')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = Conv2D(192, (3, 3), name='conv3')(x)\n",
        "    x = BatchNormalization(axis=3, epsilon=0.00001, name='bn3')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Lambda(LRN2D, name='lrn_2')(x)\n",
        "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
        "    x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
        "\n",
        "    # Inception3a\n",
        "    inception_3a_3x3 = Conv2D(96, (1, 1), name='inception_3a_3x3_conv1')(x)\n",
        "    inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn1')(inception_3a_3x3)\n",
        "    inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
        "    inception_3a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3)\n",
        "    inception_3a_3x3 = Conv2D(128, (3, 3), name='inception_3a_3x3_conv2')(inception_3a_3x3)\n",
        "    inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn2')(inception_3a_3x3)\n",
        "    inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
        "\n",
        "    inception_3a_5x5 = Conv2D(16, (1, 1), name='inception_3a_5x5_conv1')(x)\n",
        "    inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn1')(inception_3a_5x5)\n",
        "    inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
        "    inception_3a_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5)\n",
        "    inception_3a_5x5 = Conv2D(32, (5, 5), name='inception_3a_5x5_conv2')(inception_3a_5x5)\n",
        "    inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn2')(inception_3a_5x5)\n",
        "    inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
        "\n",
        "    inception_3a_pool = MaxPooling2D(pool_size=3, strides=2)(x)\n",
        "    inception_3a_pool = Conv2D(32, (1, 1), name='inception_3a_pool_conv')(inception_3a_pool)\n",
        "    inception_3a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_pool_bn')(inception_3a_pool)\n",
        "    inception_3a_pool = Activation('relu')(inception_3a_pool)\n",
        "    inception_3a_pool = ZeroPadding2D(padding=((3, 4), (3, 4)))(inception_3a_pool)\n",
        "\n",
        "    inception_3a_1x1 = Conv2D(64, (1, 1), name='inception_3a_1x1_conv')(x)\n",
        "    inception_3a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_1x1_bn')(inception_3a_1x1)\n",
        "    inception_3a_1x1 = Activation('relu')(inception_3a_1x1)\n",
        "\n",
        "    inception_3a = concatenate([inception_3a_3x3, inception_3a_5x5, inception_3a_pool, inception_3a_1x1], axis=3)\n",
        "\n",
        "    # Inception3b\n",
        "    inception_3b_3x3 = Conv2D(96, (1, 1), name='inception_3b_3x3_conv1')(inception_3a)\n",
        "    inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn1')(inception_3b_3x3)\n",
        "    inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
        "    inception_3b_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3)\n",
        "    inception_3b_3x3 = Conv2D(128, (3, 3), name='inception_3b_3x3_conv2')(inception_3b_3x3)\n",
        "    inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn2')(inception_3b_3x3)\n",
        "    inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
        "\n",
        "    inception_3b_5x5 = Conv2D(32, (1, 1), name='inception_3b_5x5_conv1')(inception_3a)\n",
        "    inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn1')(inception_3b_5x5)\n",
        "    inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
        "    inception_3b_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5)\n",
        "    inception_3b_5x5 = Conv2D(64, (5, 5), name='inception_3b_5x5_conv2')(inception_3b_5x5)\n",
        "    inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn2')(inception_3b_5x5)\n",
        "    inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
        "\n",
        "    inception_3b_pool = Lambda(lambda x: x**2, name='power2_3b')(inception_3a)\n",
        "    inception_3b_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_3b_pool)\n",
        "    inception_3b_pool = Lambda(lambda x: x*9, name='mult9_3b')(inception_3b_pool)\n",
        "    inception_3b_pool = Lambda(lambda x: tf.math.sqrt(x), name='sqrt_3b')(inception_3b_pool)\n",
        "    inception_3b_pool = Conv2D(64, (1, 1), name='inception_3b_pool_conv')(inception_3b_pool)\n",
        "    inception_3b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_pool_bn')(inception_3b_pool)\n",
        "    inception_3b_pool = Activation('relu')(inception_3b_pool)\n",
        "    inception_3b_pool = ZeroPadding2D(padding=(4, 4))(inception_3b_pool)\n",
        "\n",
        "    inception_3b_1x1 = Conv2D(64, (1, 1), name='inception_3b_1x1_conv')(inception_3a)\n",
        "    inception_3b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_1x1_bn')(inception_3b_1x1)\n",
        "    inception_3b_1x1 = Activation('relu')(inception_3b_1x1)\n",
        "\n",
        "    inception_3b = concatenate([inception_3b_3x3, inception_3b_5x5, inception_3b_pool, inception_3b_1x1], axis=3)\n",
        "\n",
        "    # Inception3c\n",
        "    inception_3c_3x3 = conv2d_bn(inception_3b,\n",
        "                                    layer='inception_3c_3x3',\n",
        "                                    cv1_out=128,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    cv2_out=256,\n",
        "                                    cv2_filter=(3, 3),\n",
        "                                    cv2_strides=(2, 2),\n",
        "                                    padding=(1, 1))\n",
        "\n",
        "    inception_3c_5x5 = conv2d_bn(inception_3b,\n",
        "                                    layer='inception_3c_5x5',\n",
        "                                    cv1_out=32,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    cv2_out=64,\n",
        "                                    cv2_filter=(5, 5),\n",
        "                                    cv2_strides=(2, 2),\n",
        "                                    padding=(2, 2))\n",
        "\n",
        "    inception_3c_pool = MaxPooling2D(pool_size=3, strides=2)(inception_3b)\n",
        "    inception_3c_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_3c_pool)\n",
        "\n",
        "    inception_3c = concatenate([inception_3c_3x3, inception_3c_5x5, inception_3c_pool], axis=3)\n",
        "\n",
        "    #inception 4a\n",
        "    inception_4a_3x3 = conv2d_bn(inception_3c,\n",
        "                                    layer='inception_4a_3x3',\n",
        "                                    cv1_out=96,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    cv2_out=192,\n",
        "                                    cv2_filter=(3, 3),\n",
        "                                    cv2_strides=(1, 1),\n",
        "                                    padding=(1, 1))\n",
        "    inception_4a_5x5 = conv2d_bn(inception_3c,\n",
        "                                    layer='inception_4a_5x5',\n",
        "                                    cv1_out=32,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    cv2_out=64,\n",
        "                                    cv2_filter=(5, 5),\n",
        "                                    cv2_strides=(1, 1),\n",
        "                                    padding=(2, 2))\n",
        "\n",
        "    inception_4a_pool = Lambda(lambda x: x**2, name='power2_4a')(inception_3c)\n",
        "    inception_4a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_4a_pool)\n",
        "    inception_4a_pool = Lambda(lambda x: x*9, name='mult9_4a')(inception_4a_pool)\n",
        "    inception_4a_pool = Lambda(lambda x: tf.math.sqrt(x), name='sqrt_4a')(inception_4a_pool)\n",
        "    inception_4a_pool = conv2d_bn(inception_4a_pool,\n",
        "                                    layer='inception_4a_pool',\n",
        "                                    cv1_out=128,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    padding=(2, 2))\n",
        "    inception_4a_1x1 = conv2d_bn(inception_3c,\n",
        "                                    layer='inception_4a_1x1',\n",
        "                                    cv1_out=256,\n",
        "                                    cv1_filter=(1, 1))\n",
        "    inception_4a = concatenate([inception_4a_3x3, inception_4a_5x5, inception_4a_pool, inception_4a_1x1], axis=3)\n",
        "\n",
        "    #inception4e\n",
        "    inception_4e_3x3 = conv2d_bn(inception_4a,\n",
        "                                    layer='inception_4e_3x3',\n",
        "                                    cv1_out=160,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    cv2_out=256,\n",
        "                                    cv2_filter=(3, 3),\n",
        "                                    cv2_strides=(2, 2),\n",
        "                                    padding=(1, 1))\n",
        "    inception_4e_5x5 = conv2d_bn(inception_4a,\n",
        "                                    layer='inception_4e_5x5',\n",
        "                                    cv1_out=64,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    cv2_out=128,\n",
        "                                    cv2_filter=(5, 5),\n",
        "                                    cv2_strides=(2, 2),\n",
        "                                    padding=(2, 2))\n",
        "    inception_4e_pool = MaxPooling2D(pool_size=3, strides=2)(inception_4a)\n",
        "    inception_4e_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_4e_pool)\n",
        "\n",
        "    inception_4e = concatenate([inception_4e_3x3, inception_4e_5x5, inception_4e_pool], axis=3)\n",
        "\n",
        "    #inception5a\n",
        "    inception_5a_3x3 = conv2d_bn(inception_4e,\n",
        "                                    layer='inception_5a_3x3',\n",
        "                                    cv1_out=96,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    cv2_out=384,\n",
        "                                    cv2_filter=(3, 3),\n",
        "                                    cv2_strides=(1, 1),\n",
        "                                    padding=(1, 1))\n",
        "\n",
        "    inception_5a_pool = Lambda(lambda x: x**2, name='power2_5a')(inception_4e)\n",
        "    inception_5a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_5a_pool)\n",
        "    inception_5a_pool = Lambda(lambda x: x*9, name='mult9_5a')(inception_5a_pool)\n",
        "    inception_5a_pool = Lambda(lambda x: tf.math.sqrt(x), name='sqrt_5a')(inception_5a_pool)\n",
        "    inception_5a_pool = conv2d_bn(inception_5a_pool,\n",
        "                                    layer='inception_5a_pool',\n",
        "                                    cv1_out=96,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    padding=(1, 1))\n",
        "    inception_5a_1x1 = conv2d_bn(inception_4e,\n",
        "                                    layer='inception_5a_1x1',\n",
        "                                    cv1_out=256,\n",
        "                                    cv1_filter=(1, 1))\n",
        "\n",
        "    inception_5a = concatenate([inception_5a_3x3, inception_5a_pool, inception_5a_1x1], axis=3)\n",
        "\n",
        "    #inception_5b\n",
        "    inception_5b_3x3 = conv2d_bn(inception_5a,\n",
        "                                    layer='inception_5b_3x3',\n",
        "                                    cv1_out=96,\n",
        "                                    cv1_filter=(1, 1),\n",
        "                                    cv2_out=384,\n",
        "                                    cv2_filter=(3, 3),\n",
        "                                    cv2_strides=(1, 1),\n",
        "                                    padding=(1, 1))\n",
        "    inception_5b_pool = MaxPooling2D(pool_size=3, strides=2)(inception_5a)\n",
        "    inception_5b_pool = conv2d_bn(inception_5b_pool,\n",
        "                                    layer='inception_5b_pool',\n",
        "                                    cv1_out=96,\n",
        "                                    cv1_filter=(1, 1))\n",
        "    inception_5b_pool = ZeroPadding2D(padding=(1, 1))(inception_5b_pool)\n",
        "\n",
        "    inception_5b_1x1 = conv2d_bn(inception_5a,\n",
        "                                    layer='inception_5b_1x1',\n",
        "                                    cv1_out=256,\n",
        "                                    cv1_filter=(1, 1))\n",
        "    inception_5b = concatenate([inception_5b_3x3, inception_5b_pool, inception_5b_1x1], axis=3)\n",
        "\n",
        "    av_pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1))(inception_5b)\n",
        "    reshape_layer = Flatten()(av_pool)\n",
        "    dense_layer = Dense(128, name='dense_layer')(reshape_layer)\n",
        "    norm_layer = Lambda(lambda  x: tf.math.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n",
        "\n",
        "    # Final Model\n",
        "    model = Model(inputs=[myInput], outputs=norm_layer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "n2YdKH1JJy9U"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "IMG_HEIGHT = 160\n",
        "IMG_WIDTH = 160\n",
        "IMG_SIZE = 160\n",
        "train_dir = \"./4 classes fer/train\"\n",
        "test_dir = \"./4 classes fer/test\"\n",
        "valid_dir = \"./4 classes fer/valid\"\n",
        "CLASS_NAMES = np.array(['anger', 'happiness', 'neutral', 'sadness'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Zpg0aOitFBeI"
      },
      "outputs": [],
      "source": [
        "data_generator = ImageDataGenerator(rescale = 1./255.,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "test_data_generator = ImageDataGenerator(rescale = 1./255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "vc0-bJJ4FOJ7",
        "outputId": "649313cd-c679-4030-fb22-a3d5557efaaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 23814 images belonging to 4 classes.\n",
            "Found 2968 images belonging to 4 classes.\n",
            "Found 2953 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data_gen = data_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=train_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "valid_data_gen = test_data_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=valid_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "test_data_gen = test_data_generator.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                               directory=test_dir,\n",
        "                                               shuffle=True,\n",
        "                                               target_size=(IMG_HEIGHT, IMG_WIDTH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "grjj4yKb_2az",
        "outputId": "115d34b9-61dd-47c7-b849-ded482916847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "Model: \"inception_resnet_v1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n",
            "                                                                 Block35_1_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Activation (Activatio (None, 17, 17, 256)  0           Block35_1_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n",
            "                                                                 Block35_2_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Activation (Activatio (None, 17, 17, 256)  0           Block35_2_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n",
            "                                                                 Block35_3_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Activation (Activatio (None, 17, 17, 256)  0           Block35_3_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n",
            "                                                                 Block35_4_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Activation (Activatio (None, 17, 17, 256)  0           Block35_4_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n",
            "                                                                 Block35_5_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Activation (Activatio (None, 17, 17, 256)  0           Block35_5_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n",
            "                                                                 Block17_1_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Activation (Activatio (None, 8, 8, 896)    0           Block17_1_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n",
            "                                                                 Block17_2_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Activation (Activatio (None, 8, 8, 896)    0           Block17_2_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_3_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_3_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_3_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_3_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_3_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_3_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_3_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_3_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_2_Activation[0][0]       \n",
            "                                                                 Block17_3_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_3_Activation (Activatio (None, 8, 8, 896)    0           Block17_3_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_4_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_4_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_4_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_4_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_4_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_4_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_4_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_4_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_3_Activation[0][0]       \n",
            "                                                                 Block17_4_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_4_Activation (Activatio (None, 8, 8, 896)    0           Block17_4_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_5_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_5_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_5_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_5_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_5_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_5_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_5_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_5_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_4_Activation[0][0]       \n",
            "                                                                 Block17_5_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_5_Activation (Activatio (None, 8, 8, 896)    0           Block17_5_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_6_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_6_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_6_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_6_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_6_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_6_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_6_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_6_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_5_Activation[0][0]       \n",
            "                                                                 Block17_6_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_6_Activation (Activatio (None, 8, 8, 896)    0           Block17_6_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_6_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_7_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_7_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_7_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_7_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_7_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_7_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_7_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_7_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_6_Activation[0][0]       \n",
            "                                                                 Block17_7_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_7_Activation (Activatio (None, 8, 8, 896)    0           Block17_7_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_7_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_8_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_8_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_8_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_8_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_8_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_8_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_8_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_8_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_7_Activation[0][0]       \n",
            "                                                                 Block17_8_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_8_Activation (Activatio (None, 8, 8, 896)    0           Block17_8_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_8_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_9_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_9_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_9_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_9_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_9_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_9_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_9_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_9_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_8_Activation[0][0]       \n",
            "                                                                 Block17_9_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_9_Activation (Activatio (None, 8, 8, 896)    0           Block17_9_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0a_1x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0a_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0a_1x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0a_1x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0b_1x7\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0b_1 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0b_1x7\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_0_Conv2d_1x1  (None, 8, 8, 128)    114688      Block17_9_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    114688      Block17_10_Branch_1_Conv2d_0b_1x7\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    384         Block17_10_Branch_0_Conv2d_1x1[0]\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    384         Block17_10_Branch_1_Conv2d_0c_7x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_0_Conv2d_1x1_ (None, 8, 8, 128)    0           Block17_10_Branch_0_Conv2d_1x1_Ba\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Branch_1_Conv2d_0c_7 (None, 8, 8, 128)    0           Block17_10_Branch_1_Conv2d_0c_7x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Concatenate (Concate (None, 8, 8, 256)    0           Block17_10_Branch_0_Conv2d_1x1_Ac\n",
            "                                                                 Block17_10_Branch_1_Conv2d_0c_7x1\n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Conv2d_1x1 (Conv2D)  (None, 8, 8, 896)    230272      Block17_10_Concatenate[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_ScaleSum (Lambda)    (None, 8, 8, 896)    0           Block17_9_Activation[0][0]       \n",
            "                                                                 Block17_10_Conv2d_1x1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_10_Activation (Activati (None, 8, 8, 896)    0           Block17_10_ScaleSum[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    229376      Block17_10_Activation[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    589824      Mixed_7a_Branch_2_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_0_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    768         Mixed_7a_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    768         Mixed_7a_Branch_2_Conv2d_0b_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_0_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_0a_1x1 (None, 8, 8, 256)    0           Mixed_7a_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_0b_3x3 (None, 8, 8, 256)    0           Mixed_7a_Branch_2_Conv2d_0b_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    884736      Mixed_7a_Branch_0_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    589824      Mixed_7a_Branch_2_Conv2d_0b_3x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    1152        Mixed_7a_Branch_0_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_1_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    768         Mixed_7a_Branch_2_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_0_Conv2d_1a_3x3 (None, 3, 3, 384)    0           Mixed_7a_Branch_0_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_1_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_1_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_2_Conv2d_1a_3x3 (None, 3, 3, 256)    0           Mixed_7a_Branch_2_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a_Branch_3_MaxPool_1a_3x (None, 3, 3, 896)    0           Block17_10_Activation[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_7a (Concatenate)          (None, 3, 3, 1792)   0           Mixed_7a_Branch_0_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_7a_Branch_1_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_7a_Branch_2_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_7a_Branch_3_MaxPool_1a_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_1_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_1_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_1_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_1_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_1_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_1_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_1_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_1_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Mixed_7a[0][0]                   \n",
            "                                                                 Block8_1_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_1_Activation (Activation (None, 3, 3, 1792)   0           Block8_1_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_1_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_2_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_2_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_2_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_2_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_2_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_2_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_2_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_2_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_1_Activation[0][0]        \n",
            "                                                                 Block8_2_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_2_Activation (Activation (None, 3, 3, 1792)   0           Block8_2_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_2_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_3_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_3_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_3_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_3_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_3_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_3_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_3_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_3_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_2_Activation[0][0]        \n",
            "                                                                 Block8_3_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_3_Activation (Activation (None, 3, 3, 1792)   0           Block8_3_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_3_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_4_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_4_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_4_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_4_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_4_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_4_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_4_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_4_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_3_Activation[0][0]        \n",
            "                                                                 Block8_4_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_4_Activation (Activation (None, 3, 3, 1792)   0           Block8_4_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_4_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_5_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_5_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_5_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_5_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_5_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_5_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_5_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_5_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_4_Activation[0][0]        \n",
            "                                                                 Block8_5_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_5_Activation (Activation (None, 3, 3, 1792)   0           Block8_5_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0a_1x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0b_1x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0b_1x3 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0b_1x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_0_Conv2d_1x1 (C (None, 3, 3, 192)    344064      Block8_5_Activation[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    110592      Block8_6_Branch_1_Conv2d_0b_1x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_0_Conv2d_1x1_Ba (None, 3, 3, 192)    576         Block8_6_Branch_0_Conv2d_1x1[0][0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    576         Block8_6_Branch_1_Conv2d_0c_3x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_0_Conv2d_1x1_Ac (None, 3, 3, 192)    0           Block8_6_Branch_0_Conv2d_1x1_Batc\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Branch_1_Conv2d_0c_3x1 (None, 3, 3, 192)    0           Block8_6_Branch_1_Conv2d_0c_3x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Concatenate (Concatena (None, 3, 3, 384)    0           Block8_6_Branch_0_Conv2d_1x1_Acti\n",
            "                                                                 Block8_6_Branch_1_Conv2d_0c_3x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_Conv2d_1x1 (Conv2D)    (None, 3, 3, 1792)   689920      Block8_6_Concatenate[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block8_6_ScaleSum (Lambda)      (None, 3, 3, 1792)   0           Block8_5_Activation[0][0]        \n",
            "                                                                 Block8_6_Conv2d_1x1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "AvgPool (GlobalAveragePooling2D (None, 1792)         0           Block8_6_ScaleSum[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Dropout (Dropout)               (None, 1792)         0           AvgPool[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck (Dense)              (None, 128)          229376      Dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_BatchNorm (BatchNorm (None, 128)          384         Bottleneck[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 22,808,144\n",
            "Trainable params: 22,779,312\n",
            "Non-trainable params: 28,832\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "faceNet = tf.keras.models.load_model('./drive/My Drive/Models/keras-facenet/model/facenet_keras.h5')\n",
        "faceNet.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_v6vsnvSIaOz"
      },
      "outputs": [],
      "source": [
        "nn4 = facenet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "8-5ZP_KZMHdZ",
        "outputId": "3f180e36-c213-49b9-e3cc-7511a7be3acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 102, 102, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 48, 48, 64)   9472        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, 48, 48, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 48, 48, 64)   0           bn1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 50, 50, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 24, 24, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lrn_1 (Lambda)                  (None, 24, 24, 64)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 24, 24, 64)   4160        lrn_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2 (BatchNormalization)        (None, 24, 24, 64)   256         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 24, 24, 64)   0           bn2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 26, 26, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 24, 24, 192)  110784      zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn3 (BatchNormalization)        (None, 24, 24, 192)  768         conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 24, 24, 192)  0           bn3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "lrn_2 (Lambda)                  (None, 24, 24, 192)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 26, 26, 192)  0           lrn_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 192)  0           zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_3x3_conv1 (Conv2D) (None, 12, 12, 96)   18528       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_5x5_conv1 (Conv2D) (None, 12, 12, 16)   3088        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3a_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_5x5_bn1 (BatchNorm (None, 12, 12, 16)   64          inception_3a_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 12, 12, 96)   0           inception_3a_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 12, 12, 16)   0           inception_3a_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 192)    0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 14, 14, 96)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 16, 16, 16)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_pool_conv (Conv2D) (None, 5, 5, 32)     6176        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_5x5_conv2 (Conv2D) (None, 12, 12, 32)   12832       zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_pool_bn (BatchNorm (None, 5, 5, 32)     128         inception_3a_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_1x1_conv (Conv2D)  (None, 12, 12, 64)   12352       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3a_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_5x5_bn2 (BatchNorm (None, 12, 12, 32)   128         inception_3a_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 5, 5, 32)     0           inception_3a_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 12, 12, 128)  0           inception_3a_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 12, 12, 32)   0           inception_3a_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, 12, 12, 32)   0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 12, 12, 64)   0           inception_3a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 12, 12, 256)  0           activation_4[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "                                                                 zero_padding2d_6[0][0]           \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "power2_3b (Lambda)              (None, 12, 12, 256)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_3x3_conv1 (Conv2D) (None, 12, 12, 96)   24672       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_5x5_conv1 (Conv2D) (None, 12, 12, 32)   8224        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 4, 4, 256)    0           power2_3b[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3b_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3b_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mult9_3b (Lambda)               (None, 4, 4, 256)    0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 12, 12, 96)   0           inception_3b_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 12, 12, 32)   0           inception_3b_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sqrt_3b (Lambda)                (None, 4, 4, 256)    0           mult9_3b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, 14, 14, 96)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPadding2D (None, 16, 16, 32)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_pool_conv (Conv2D) (None, 4, 4, 64)     16448       sqrt_3b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_5x5_conv2 (Conv2D) (None, 12, 12, 64)   51264       zero_padding2d_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_pool_bn (BatchNorm (None, 4, 4, 64)     256         inception_3b_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_1x1_conv (Conv2D)  (None, 12, 12, 64)   16448       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3b_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_5x5_bn2 (BatchNorm (None, 12, 12, 64)   256         inception_3b_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 4, 4, 64)     0           inception_3b_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 12, 12, 128)  0           inception_3b_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 12, 12, 64)   0           inception_3b_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, 12, 12, 64)   0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 12, 12, 64)   0           inception_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 12, 12, 320)  0           activation_10[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "                                                                 zero_padding2d_9[0][0]           \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_3x3_conv1 (Conv2D) (None, 12, 12, 128)  41088       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_5x5_conv1 (Conv2D) (None, 12, 12, 32)   10272       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_3x3_bn1 (BatchNorm (None, 12, 12, 128)  512         inception_3c_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3c_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 12, 12, 128)  0           inception_3c_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 12, 12, 32)   0           inception_3c_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, 14, 14, 128)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, 16, 16, 32)   0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_3x3_conv2 (Conv2D) (None, 6, 6, 256)    295168      zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_3x3_bn2 (BatchNorm (None, 6, 6, 256)    1024        inception_3c_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_3c_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 320)    0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 6, 6, 256)    0           inception_3c_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 6, 6, 64)     0           inception_3c_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPadding2 (None, 6, 6, 320)    0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 6, 6, 640)    0           activation_16[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 zero_padding2d_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "power2_4a (Lambda)              (None, 6, 6, 640)    0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_3x3_conv1 (Conv2D) (None, 6, 6, 96)     61536       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_5x5_conv1 (Conv2D) (None, 6, 6, 32)     20512       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 2, 2, 640)    0           power2_4a[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_3x3_bn1 (BatchNorm (None, 6, 6, 96)     384         inception_4a_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_5x5_bn1 (BatchNorm (None, 6, 6, 32)     128         inception_4a_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mult9_4a (Lambda)               (None, 2, 2, 640)    0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 6, 6, 96)     0           inception_4a_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 6, 6, 32)     0           inception_4a_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sqrt_4a (Lambda)                (None, 2, 2, 640)    0           mult9_4a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPadding2 (None, 8, 8, 96)     0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPadding2 (None, 10, 10, 32)   0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_pool_conv (Conv2D) (None, 2, 2, 128)    82048       sqrt_4a[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_3x3_conv2 (Conv2D) (None, 6, 6, 192)    166080      zero_padding2d_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_pool_bn (BatchNorm (None, 2, 2, 128)    512         inception_4a_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_1x1_conv (Conv2D)  (None, 6, 6, 256)    164096      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_3x3_bn2 (BatchNorm (None, 6, 6, 192)    768         inception_4a_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_4a_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 2, 2, 128)    0           inception_4a_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_1x1_bn (BatchNorma (None, 6, 6, 256)    1024        inception_4a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 6, 6, 192)    0           inception_4a_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 6, 6, 64)     0           inception_4a_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_15 (ZeroPadding2 (None, 6, 6, 128)    0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 6, 6, 256)    0           inception_4a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 6, 6, 640)    0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 zero_padding2d_15[0][0]          \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_3x3_conv1 (Conv2D) (None, 6, 6, 160)    102560      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_5x5_conv1 (Conv2D) (None, 6, 6, 64)     41024       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_3x3_bn1 (BatchNorm (None, 6, 6, 160)    640         inception_4e_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_5x5_bn1 (BatchNorm (None, 6, 6, 64)     256         inception_4e_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 6, 6, 160)    0           inception_4e_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 6, 6, 64)     0           inception_4e_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_16 (ZeroPadding2 (None, 8, 8, 160)    0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_17 (ZeroPadding2 (None, 10, 10, 64)   0           activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_3x3_conv2 (Conv2D) (None, 3, 3, 256)    368896      zero_padding2d_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_5x5_conv2 (Conv2D) (None, 3, 3, 128)    204928      zero_padding2d_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_3x3_bn2 (BatchNorm (None, 3, 3, 256)    1024        inception_4e_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_5x5_bn2 (BatchNorm (None, 3, 3, 128)    512         inception_4e_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 640)    0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 256)    0           inception_4e_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 3, 3, 128)    0           inception_4e_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_18 (ZeroPadding2 (None, 3, 3, 640)    0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 3, 3, 1024)   0           activation_26[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "                                                                 zero_padding2d_18[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "power2_5a (Lambda)              (None, 3, 3, 1024)   0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_3x3_conv1 (Conv2D) (None, 3, 3, 96)     98400       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 1024)   0           power2_5a[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5a_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mult9_5a (Lambda)               (None, 1, 1, 1024)   0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 96)     0           inception_5a_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sqrt_5a (Lambda)                (None, 1, 1, 1024)   0           mult9_5a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_19 (ZeroPadding2 (None, 5, 5, 96)     0           activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_pool_conv (Conv2D) (None, 1, 1, 96)     98400       sqrt_5a[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_19[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5a_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_1x1_conv (Conv2D)  (None, 3, 3, 256)    262400      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5a_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 1, 1, 96)     0           inception_5a_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 384)    0           inception_5a_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_20 (ZeroPadding2 (None, 3, 3, 96)     0           activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 256)    0           inception_5a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 3, 3, 736)    0           activation_30[0][0]              \n",
            "                                                                 zero_padding2d_20[0][0]          \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_3x3_conv1 (Conv2D) (None, 3, 3, 96)     70752       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5b_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 96)     0           inception_5b_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 736)    0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_21 (ZeroPadding2 (None, 5, 5, 96)     0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_pool_conv (Conv2D) (None, 1, 1, 96)     70752       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_21[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5b_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_1x1_conv (Conv2D)  (None, 3, 3, 256)    188672      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5b_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 1, 1, 96)     0           inception_5b_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 384)    0           inception_5b_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_22 (ZeroPadding2 (None, 3, 3, 96)     0           activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 256)    0           inception_5b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 3, 3, 736)    0           activation_34[0][0]              \n",
            "                                                                 zero_padding2d_22[0][0]          \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 736)    0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 736)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_layer (Dense)             (None, 128)          94336       flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_layer (Lambda)             (None, 128)          0           dense_layer[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 3,743,280\n",
            "Trainable params: 3,733,968\n",
            "Non-trainable params: 9,312\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "nn4.load_weights('./drive/My Drive/Models/nn4.small2.v1.h5')\n",
        "nn4.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "DHAe9epLGz--"
      },
      "outputs": [],
      "source": [
        "for layer in faceNet.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "E-TDRcbMtuRm"
      },
      "outputs": [],
      "source": [
        "# tf.keras.utils.plot_model(faceNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "v0EG_Mxa54i2",
        "outputId": "14d8fbfe-3693-4efe-ccc1-3fb71080d5ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.core.Activation at 0x7f83f69d42b0>"
            ]
          },
          "execution_count": 41,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "faceNet.get_layer(name=\"Block17_10_Activation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "HmqG9_S8CjOo",
        "outputId": "34618bca-dfa2-4801-92fc-0d29a14a82e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n",
            "                                                                 Block35_1_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Activation (Activatio (None, 17, 17, 256)  0           Block35_1_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n",
            "                                                                 Block35_2_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Activation (Activatio (None, 17, 17, 256)  0           Block35_2_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n",
            "                                                                 Block35_3_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Activation (Activatio (None, 17, 17, 256)  0           Block35_3_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n",
            "                                                                 Block35_4_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Activation (Activatio (None, 17, 17, 256)  0           Block35_4_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n",
            "                                                                 Block35_5_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Activation (Activatio (None, 17, 17, 256)  0           Block35_5_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n",
            "                                                                 Block17_1_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Activation (Activatio (None, 8, 8, 896)    0           Block17_1_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n",
            "                                                                 Block17_2_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Activation (Activatio (None, 8, 8, 896)    0           Block17_2_ScaleSum[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 4,096,592\n",
            "Trainable params: 0\n",
            "Non-trainable params: 4,096,592\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "base_model = keras.models.Model(inputs=faceNet.input, outputs=faceNet.get_layer(name=\"Block17_2_Activation\").output)\n",
        "base_model.trainable = False\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CaEPYnK97rXt"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, growth_rate, name):\n",
        "  \"\"\"A building block for a dense block.\n",
        "  # Arguments\n",
        "      x: input tensor.\n",
        "      growth_rate: float, growth rate at dense layers.\n",
        "      name: string, block label.\n",
        "  # Returns\n",
        "      Output tensor for the block.\n",
        "  \"\"\"\n",
        "  x1 = layers.BatchNormalization(epsilon=1.001e-5,\n",
        "                                  name=name + '_0_bn')(x)\n",
        "  x1 = layers.ReLU(max_value=6., name=name + '_0_relu')(x1)\n",
        "  x1 = layers.Dropout(0.2)(x1)\n",
        "  x1 = layers.Conv2D(4 * growth_rate, 1,\n",
        "                      use_bias=False,\n",
        "                      name=name + '_1_conv')(x1)\n",
        "  x1 = layers.BatchNormalization(epsilon=1.001e-5,\n",
        "                                  name=name + '_1_bn')(x1)\n",
        "  x1 = layers.ReLU(max_value=6., name=name + '_1_relu')(x1)\n",
        "  x1 = layers.Dropout(0.2)(x1)\n",
        "  x1 = layers.Conv2D(growth_rate, 3,\n",
        "                      padding='same',\n",
        "                      use_bias=False,\n",
        "                      name=name + '_2_conv')(x1)\n",
        "  x = layers.Concatenate(name=name + '_concat')([x, x1])\n",
        "  return x\n",
        "\n",
        "def dense_block(x, blocks, name, growth=64):\n",
        "  \"\"\"A dense block.\n",
        "  # Arguments\n",
        "      x: input tensor.\n",
        "      blocks: integer, the number of building blocks.\n",
        "      name: string, block label.\n",
        "  # Returns\n",
        "      output tensor for the block.\n",
        "  \"\"\"\n",
        "  for i in range(blocks):\n",
        "      x = conv_block(x, growth, name=name + '_block' + str(i + 1))\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "zlNtilYcpDm_",
        "outputId": "a7ccab14-4fac-4473-f733-e14d49253062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 160, 160, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3 (Conv2D)          (None, 79, 79, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3_BatchNorm (BatchN (None, 79, 79, 32)   96          Conv2d_1a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_1a_3x3_Activation (Activ (None, 79, 79, 32)   0           Conv2d_1a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3 (Conv2D)          (None, 77, 77, 32)   9216        Conv2d_1a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3_BatchNorm (BatchN (None, 77, 77, 32)   96          Conv2d_2a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2a_3x3_Activation (Activ (None, 77, 77, 32)   0           Conv2d_2a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3 (Conv2D)          (None, 77, 77, 64)   18432       Conv2d_2a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3_BatchNorm (BatchN (None, 77, 77, 64)   192         Conv2d_2b_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_2b_3x3_Activation (Activ (None, 77, 77, 64)   0           Conv2d_2b_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "MaxPool_3a_3x3 (MaxPooling2D)   (None, 38, 38, 64)   0           Conv2d_2b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1 (Conv2D)          (None, 38, 38, 80)   5120        MaxPool_3a_3x3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1_BatchNorm (BatchN (None, 38, 38, 80)   240         Conv2d_3b_1x1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_3b_1x1_Activation (Activ (None, 38, 38, 80)   0           Conv2d_3b_1x1_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3 (Conv2D)          (None, 36, 36, 192)  138240      Conv2d_3b_1x1_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3_BatchNorm (BatchN (None, 36, 36, 192)  576         Conv2d_4a_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4a_3x3_Activation (Activ (None, 36, 36, 192)  0           Conv2d_4a_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3 (Conv2D)          (None, 17, 17, 256)  442368      Conv2d_4a_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3_BatchNorm (BatchN (None, 17, 17, 256)  768         Conv2d_4b_3x3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Conv2d_4b_3x3_Activation (Activ (None, 17, 17, 256)  0           Conv2d_4b_3x3_BatchNorm[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Conv2d_4b_3x3_Activation[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_1_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_1_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_1_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_1_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_1_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_1_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_1_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_1_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_1_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_1_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_1_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Conv2d_4b_3x3_Activation[0][0]   \n",
            "                                                                 Block35_1_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_1_Activation (Activatio (None, 17, 17, 256)  0           Block35_1_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_2_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_2_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_2_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_2_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_2_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_2_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_2_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_2_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_2_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_2_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_2_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_1_Activation[0][0]       \n",
            "                                                                 Block35_2_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_2_Activation (Activatio (None, 17, 17, 256)  0           Block35_2_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_3_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_3_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_3_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_3_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_3_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_3_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_3_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_3_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_3_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_3_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_3_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_3_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_2_Activation[0][0]       \n",
            "                                                                 Block35_3_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_3_Activation (Activatio (None, 17, 17, 256)  0           Block35_3_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_3_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_4_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_4_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_4_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_4_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_4_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_4_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_4_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_4_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_4_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_4_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_4_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_4_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_3_Activation[0][0]       \n",
            "                                                                 Block35_4_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_4_Activation (Activatio (None, 17, 17, 256)  0           Block35_4_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0a_1x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1 ( (None, 17, 17, 32)   8192        Block35_4_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   9216        Block35_5_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   9216        Block35_5_Branch_2_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1_B (None, 17, 17, 32)   96          Block35_5_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   96          Block35_5_Branch_1_Conv2d_0b_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   96          Block35_5_Branch_2_Conv2d_0c_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_0_Conv2d_1x1_A (None, 17, 17, 32)   0           Block35_5_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_1_Conv2d_0b_3x (None, 17, 17, 32)   0           Block35_5_Branch_1_Conv2d_0b_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Branch_2_Conv2d_0c_3x (None, 17, 17, 32)   0           Block35_5_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Concatenate (Concaten (None, 17, 17, 96)   0           Block35_5_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block35_5_Branch_1_Conv2d_0b_3x3_\n",
            "                                                                 Block35_5_Branch_2_Conv2d_0c_3x3_\n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Conv2d_1x1 (Conv2D)   (None, 17, 17, 256)  24832       Block35_5_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_ScaleSum (Lambda)     (None, 17, 17, 256)  0           Block35_4_Activation[0][0]       \n",
            "                                                                 Block35_5_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block35_5_Activation (Activatio (None, 17, 17, 256)  0           Block35_5_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  49152       Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0a_1x1[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0a_1x1 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0a_1x1_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  331776      Mixed_6a_Branch_1_Conv2d_0a_1x1_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  576         Mixed_6a_Branch_1_Conv2d_0b_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_0b_3x3 (None, 17, 17, 192)  0           Mixed_6a_Branch_1_Conv2d_0b_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    884736      Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    442368      Mixed_6a_Branch_1_Conv2d_0b_3x3_A\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    1152        Mixed_6a_Branch_0_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    768         Mixed_6a_Branch_1_Conv2d_1a_3x3[0\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_0_Conv2d_1a_3x3 (None, 8, 8, 384)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_1_Conv2d_1a_3x3 (None, 8, 8, 256)    0           Mixed_6a_Branch_1_Conv2d_1a_3x3_B\n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a_Branch_2_MaxPool_1a_3x (None, 8, 8, 256)    0           Block35_5_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Mixed_6a (Concatenate)          (None, 8, 8, 896)    0           Mixed_6a_Branch_0_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_6a_Branch_1_Conv2d_1a_3x3_A\n",
            "                                                                 Mixed_6a_Branch_2_MaxPool_1a_3x3[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_1_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_1_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_1_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_1_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_1_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_1_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_1_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_1_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Mixed_6a[0][0]                   \n",
            "                                                                 Block17_1_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_1_Activation (Activatio (None, 8, 8, 896)    0           Block17_1_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0a_1x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0a_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0a_1x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0b_1x7[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0b_1x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1 ( (None, 8, 8, 128)    114688      Block17_1_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    114688      Block17_2_Branch_1_Conv2d_0b_1x7_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1_B (None, 8, 8, 128)    384         Block17_2_Branch_0_Conv2d_1x1[0][\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    384         Block17_2_Branch_1_Conv2d_0c_7x1[\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_0_Conv2d_1x1_A (None, 8, 8, 128)    0           Block17_2_Branch_0_Conv2d_1x1_Bat\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Branch_1_Conv2d_0c_7x (None, 8, 8, 128)    0           Block17_2_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Concatenate (Concaten (None, 8, 8, 256)    0           Block17_2_Branch_0_Conv2d_1x1_Act\n",
            "                                                                 Block17_2_Branch_1_Conv2d_0c_7x1_\n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Conv2d_1x1 (Conv2D)   (None, 8, 8, 896)    230272      Block17_2_Concatenate[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_ScaleSum (Lambda)     (None, 8, 8, 896)    0           Block17_1_Activation[0][0]       \n",
            "                                                                 Block17_2_Conv2d_1x1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "Block17_2_Activation (Activatio (None, 8, 8, 896)    0           Block17_2_ScaleSum[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_38 (Dropout)            (None, 8, 8, 896)    0           Block17_2_Activation[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 512)    458752      dropout_38[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block1_0_bn (BatchNormal (None, 8, 8, 512)    2048        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block1_0_relu (ReLU)     (None, 8, 8, 512)    0           dense1_block1_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 8, 8, 512)    0           dense1_block1_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block1_1_conv (Conv2D)   (None, 8, 8, 256)    131072      dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block1_1_bn (BatchNormal (None, 8, 8, 256)    1024        dense1_block1_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block1_1_relu (ReLU)     (None, 8, 8, 256)    0           dense1_block1_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 8, 8, 256)    0           dense1_block1_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block1_2_conv (Conv2D)   (None, 8, 8, 64)     147456      dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block1_concat (Concatena (None, 8, 8, 576)    0           conv2d_14[0][0]                  \n",
            "                                                                 dense1_block1_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block2_0_bn (BatchNormal (None, 8, 8, 576)    2304        dense1_block1_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block2_0_relu (ReLU)     (None, 8, 8, 576)    0           dense1_block2_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 8, 8, 576)    0           dense1_block2_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block2_1_conv (Conv2D)   (None, 8, 8, 256)    147456      dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block2_1_bn (BatchNormal (None, 8, 8, 256)    1024        dense1_block2_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block2_1_relu (ReLU)     (None, 8, 8, 256)    0           dense1_block2_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 8, 8, 256)    0           dense1_block2_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block2_2_conv (Conv2D)   (None, 8, 8, 64)     147456      dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block2_concat (Concatena (None, 8, 8, 640)    0           dense1_block1_concat[0][0]       \n",
            "                                                                 dense1_block2_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block3_0_bn (BatchNormal (None, 8, 8, 640)    2560        dense1_block2_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block3_0_relu (ReLU)     (None, 8, 8, 640)    0           dense1_block3_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 8, 8, 640)    0           dense1_block3_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block3_1_conv (Conv2D)   (None, 8, 8, 256)    163840      dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block3_1_bn (BatchNormal (None, 8, 8, 256)    1024        dense1_block3_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block3_1_relu (ReLU)     (None, 8, 8, 256)    0           dense1_block3_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 8, 8, 256)    0           dense1_block3_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block3_2_conv (Conv2D)   (None, 8, 8, 64)     147456      dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block3_concat (Concatena (None, 8, 8, 704)    0           dense1_block2_concat[0][0]       \n",
            "                                                                 dense1_block3_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block4_0_bn (BatchNormal (None, 8, 8, 704)    2816        dense1_block3_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block4_0_relu (ReLU)     (None, 8, 8, 704)    0           dense1_block4_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 8, 8, 704)    0           dense1_block4_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block4_1_conv (Conv2D)   (None, 8, 8, 256)    180224      dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block4_1_bn (BatchNormal (None, 8, 8, 256)    1024        dense1_block4_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block4_1_relu (ReLU)     (None, 8, 8, 256)    0           dense1_block4_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 8, 8, 256)    0           dense1_block4_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block4_2_conv (Conv2D)   (None, 8, 8, 64)     147456      dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block4_concat (Concatena (None, 8, 8, 768)    0           dense1_block3_concat[0][0]       \n",
            "                                                                 dense1_block4_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block5_0_bn (BatchNormal (None, 8, 8, 768)    3072        dense1_block4_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block5_0_relu (ReLU)     (None, 8, 8, 768)    0           dense1_block5_0_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 8, 8, 768)    0           dense1_block5_0_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block5_1_conv (Conv2D)   (None, 8, 8, 256)    196608      dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block5_1_bn (BatchNormal (None, 8, 8, 256)    1024        dense1_block5_1_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block5_1_relu (ReLU)     (None, 8, 8, 256)    0           dense1_block5_1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 8, 8, 256)    0           dense1_block5_1_relu[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block5_2_conv (Conv2D)   (None, 8, 8, 64)     147456      dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense1_block5_concat (Concatena (None, 8, 8, 832)    0           dense1_block4_concat[0][0]       \n",
            "                                                                 dense1_block5_2_conv[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 832)    3328        dense1_block5_concat[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 8, 8, 832)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 832)          0           re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 832)          0           global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 512)          426496      dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 512)          2048        dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 512)          0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 16)           8208        re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_l2_normalize_2/Squa [(None, 16)]         0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_l2_normalize_2/Sum  [(None, 1)]          0           tf_op_layer_l2_normalize_2/Square\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_l2_normalize_2/Maxi [(None, 1)]          0           tf_op_layer_l2_normalize_2/Sum[0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_l2_normalize_2/Rsqr [(None, 1)]          0           tf_op_layer_l2_normalize_2/Maximu\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_l2_normalize_2 (Ten [(None, 16)]         0           dense_6[0][0]                    \n",
            "                                                                 tf_op_layer_l2_normalize_2/Rsqrt[\n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 4)            68          tf_op_layer_l2_normalize_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 6,569,892\n",
            "Trainable params: 2,461,652\n",
            "Non-trainable params: 4,108,240\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.regularizers import l2\n",
        "\n",
        "x = base_model.output\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Conv2D(512, 1, padding='same', use_bias=False)(x)\n",
        "x = dense_block(x, 5, name=\"dense1\")\n",
        "x = keras.layers.BatchNormalization(epsilon=1.001e-5)(x)\n",
        "x = keras.layers.ReLU(max_value=6.)(x)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "x = keras.layers.Dense(512)(x)\n",
        "x = keras.layers.BatchNormalization(epsilon=1.001e-5)(x)\n",
        "x = keras.layers.ReLU(max_value=6.)(x)\n",
        "x = keras.layers.Dense(16)(x)\n",
        "x = tf.math.l2_normalize(x, axis=-1)\n",
        "x = keras.layers.Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = keras.models.Model(inputs=base_model.input, outputs=x)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "I2Lo4_uweejk"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "h3J590me2TGx"
      },
      "outputs": [],
      "source": [
        "class FECLoss(keras.losses.Loss):\n",
        "  def __init__(\n",
        "      self,\n",
        "      reduction=losses_utils.ReductionV2.AUTO,\n",
        "      name='fec_loss',\n",
        "      margin=0.1,\n",
        "  ):\n",
        "    super(FECLoss, self).__init__()\n",
        "    self.margin = margin\n",
        "\n",
        "  def call(self, labels, embeddings):\n",
        "    \n",
        "    ## assuming embeddings shape is (BATCH_SIZE, 3, EMBEDDING_SIZE)\n",
        "    e_I1 = embeddings[:, 0, :]\n",
        "    e_I2 = embeddings[:, 1, :]\n",
        "    e_I3 = embeddings[:, 2, :]\n",
        "    \n",
        "    ## I1 & I2 are the most simmiliar pair\n",
        "    d_pos = tf.reduce_sum(tf.square(e_I1 - e_I2), axis=-1)\n",
        "    d_neg1 = tf.reduce_sum(tf.square(e_I1 - e_I3), axis=-1)\n",
        "    d_neg2 = tf.reduce_sum(tf.square(e_I2 - e_I3), axis=-1)\n",
        "    \n",
        "    loss = tf.maximum(0, d_pos - d_neg1 + self.margin) + tf.maximum(0, d_pos - d_neg2 + self.margin)\n",
        "    \n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wqFVTYNfRpil"
      },
      "outputs": [],
      "source": [
        "num_train = 23814\n",
        "num_test = 2968\n",
        "num_valid = 2953\n",
        "steps_per_epoch = round(num_train)//BATCH_SIZE\n",
        "validation_steps = round(num_valid)//BATCH_SIZE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cHLuGp-gpJ3j"
      },
      "outputs": [],
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.01,\n",
        "  decay_steps=steps_per_epoch*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZKsMF74AE3ta"
      },
      "outputs": [],
      "source": [
        "# model.reset_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "7DBEzrIAowDX",
        "outputId": "c0193083-1d0b-4c76-b2a7-61518c1e6ec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 4s 157ms/step - loss: 1.4521 - accuracy: 0.1095\n",
            "24/24 [==============================] - 3s 121ms/step - loss: 1.4585 - accuracy: 0.1087\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.4585110793511074, 0.10870302]"
            ]
          },
          "execution_count": 85,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(valid_data_gen)\n",
        "model.evaluate(test_data_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "colab_type": "code",
        "id": "PFz-K9Y-SCwQ",
        "outputId": "3843c2ec-f759-4a6b-c21e-5444df3c59d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "186/186 [==============================] - 161s 868ms/step - loss: 0.9301 - accuracy: 0.6383 - val_loss: 0.7833 - val_accuracy: 0.6970\n",
            "Epoch 2/100\n",
            "186/186 [==============================] - 161s 867ms/step - loss: 0.7197 - accuracy: 0.7176 - val_loss: 0.9591 - val_accuracy: 0.6437\n",
            "Epoch 3/100\n",
            "186/186 [==============================] - 161s 864ms/step - loss: 0.6566 - accuracy: 0.7472 - val_loss: 0.8425 - val_accuracy: 0.6814\n",
            "Epoch 4/100\n",
            "186/186 [==============================] - 160s 860ms/step - loss: 0.6215 - accuracy: 0.7568 - val_loss: 0.8335 - val_accuracy: 0.6817\n",
            "Epoch 5/100\n",
            " 80/186 [===========>..................] - ETA: 1:25 - loss: 0.5830 - accuracy: 0.7694"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-dc2e1161e439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_data_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./drive/My Drive/Models/facenet_17_3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m           \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[1;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    576\u001b[0m   \u001b[0muse_cudnn_on_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m   \u001b[0mdata_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m   \u001b[0mshape_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m   \u001b[0;31m# We call the gen_nn_ops backprop functions instead of nn_ops backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m    503\u001b[0m   \"\"\"\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape_n\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9032\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   9033\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ShapeN\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9034\u001b[0;31m         name, _ctx._post_execution_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   9035\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9036\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=7, restore_best_weights=True)\n",
        "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau('val_loss', factor=0.1,\n",
        "#                                   patience=1, verbose=1)\n",
        "\n",
        "history = model.fit_generator(train_data_gen,\n",
        "                    callbacks=[callback],\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=100,\n",
        "                    validation_data=valid_data_gen,\n",
        "                    validation_steps=validation_steps)\n",
        "model.save(\"./drive/My Drive/Models/facenet_17_3\")\n",
        "model.evaluate(test_data_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "8uHVLYgn7Tkd",
        "outputId": "44a56dda-7452-47f7-943c-9b8fcefd62b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.18670171, 0.15642819, 0.4284109 , 0.22845925],\n",
              "       [0.18666367, 0.15642488, 0.42846492, 0.22844653],\n",
              "       [0.18670273, 0.15648375, 0.42838904, 0.22842447],\n",
              "       [0.1867313 , 0.1564377 , 0.42836025, 0.22847071],\n",
              "       [0.18673845, 0.15636547, 0.42838258, 0.22851354],\n",
              "       [0.18672101, 0.15646353, 0.42836848, 0.22844699],\n",
              "       [0.18673615, 0.15639958, 0.42836305, 0.22850126],\n",
              "       [0.18679886, 0.15638994, 0.42830285, 0.22850832],\n",
              "       [0.18674608, 0.15637779, 0.42835718, 0.228519  ],\n",
              "       [0.18673407, 0.15647492, 0.42835316, 0.2284379 ],\n",
              "       [0.18674864, 0.1563789 , 0.42837024, 0.22850218],\n",
              "       [0.18671311, 0.15644813, 0.42839894, 0.2284398 ],\n",
              "       [0.18677692, 0.1564516 , 0.42830262, 0.22846887],\n",
              "       [0.18668036, 0.15648668, 0.4284244 , 0.2284085 ],\n",
              "       [0.18673846, 0.1563238 , 0.42837885, 0.22855887],\n",
              "       [0.1867107 , 0.15630254, 0.42842537, 0.22856139],\n",
              "       [0.18674244, 0.1564221 , 0.4283666 , 0.22846887],\n",
              "       [0.18672568, 0.15631269, 0.42841327, 0.22854841],\n",
              "       [0.18670449, 0.15641554, 0.42839   , 0.22849002],\n",
              "       [0.18672526, 0.1564396 , 0.4283692 , 0.22846597],\n",
              "       [0.18672575, 0.15640219, 0.42837995, 0.22849211],\n",
              "       [0.18672755, 0.15644687, 0.42836416, 0.22846143],\n",
              "       [0.18662848, 0.15631305, 0.42852962, 0.22852884],\n",
              "       [0.18670762, 0.15650505, 0.42836288, 0.22842439],\n",
              "       [0.186671  , 0.15639849, 0.42844865, 0.22848184],\n",
              "       [0.18671672, 0.15645555, 0.4283901 , 0.2284376 ],\n",
              "       [0.18676904, 0.15640758, 0.42833367, 0.22848971],\n",
              "       [0.18672062, 0.15652531, 0.428358  , 0.22839615],\n",
              "       [0.1867246 , 0.15642391, 0.42837828, 0.2284732 ],\n",
              "       [0.18677482, 0.1564602 , 0.42831433, 0.22845063],\n",
              "       [0.18669926, 0.15641983, 0.42840382, 0.2284771 ],\n",
              "       [0.18669698, 0.15633495, 0.42842686, 0.22854131],\n",
              "       [0.18674226, 0.15654439, 0.42834026, 0.2283731 ],\n",
              "       [0.18675704, 0.15652873, 0.42831582, 0.22839846],\n",
              "       [0.18674088, 0.15634042, 0.42837074, 0.2285479 ],\n",
              "       [0.18672203, 0.15641864, 0.42837092, 0.2284884 ],\n",
              "       [0.18673131, 0.15638873, 0.42837837, 0.22850162],\n",
              "       [0.18676747, 0.15639251, 0.42834228, 0.22849776],\n",
              "       [0.1867051 , 0.1564835 , 0.42838746, 0.2284239 ],\n",
              "       [0.18674107, 0.1564867 , 0.42833874, 0.22843347],\n",
              "       [0.18673582, 0.15647306, 0.4283433 , 0.22844777],\n",
              "       [0.18667683, 0.1565037 , 0.42841548, 0.22840397],\n",
              "       [0.18673047, 0.15635456, 0.4283822 , 0.2285328 ],\n",
              "       [0.1867002 , 0.15636809, 0.42841682, 0.22851492],\n",
              "       [0.186726  , 0.1564198 , 0.4283679 , 0.22848624],\n",
              "       [0.18672362, 0.15641478, 0.42838013, 0.22848143],\n",
              "       [0.18669368, 0.1563987 , 0.42841896, 0.22848862],\n",
              "       [0.18669508, 0.15635121, 0.42843717, 0.2285166 ],\n",
              "       [0.18675394, 0.15647495, 0.42833227, 0.22843885],\n",
              "       [0.18669161, 0.15642618, 0.42844924, 0.22843297],\n",
              "       [0.18676038, 0.15636328, 0.42835623, 0.22852011],\n",
              "       [0.18666545, 0.15639807, 0.42845455, 0.22848193],\n",
              "       [0.18673967, 0.15645038, 0.4283362 , 0.22847378],\n",
              "       [0.18674009, 0.15648888, 0.42833152, 0.22843952],\n",
              "       [0.18669456, 0.15654372, 0.42838427, 0.2283774 ],\n",
              "       [0.18669212, 0.15638857, 0.42842966, 0.22848965],\n",
              "       [0.18674627, 0.15640132, 0.4283523 , 0.2285001 ],\n",
              "       [0.18670559, 0.15646748, 0.42839822, 0.22842863],\n",
              "       [0.18674721, 0.15647203, 0.42834195, 0.22843869],\n",
              "       [0.18675709, 0.15641674, 0.42836252, 0.22846355],\n",
              "       [0.18672146, 0.15644398, 0.42837813, 0.22845638],\n",
              "       [0.1867006 , 0.1564762 , 0.42839533, 0.22842781],\n",
              "       [0.1867323 , 0.15638474, 0.42838922, 0.2284938 ],\n",
              "       [0.1866761 , 0.15635256, 0.42846632, 0.22850497],\n",
              "       [0.1867571 , 0.15637912, 0.42833802, 0.22852573],\n",
              "       [0.18671376, 0.1565723 , 0.4283899 , 0.22832401],\n",
              "       [0.18671446, 0.1563856 , 0.42840004, 0.22849989],\n",
              "       [0.18671517, 0.1564004 , 0.4283909 , 0.22849353],\n",
              "       [0.18669859, 0.15635155, 0.4284224 , 0.22852747],\n",
              "       [0.1867575 , 0.1564943 , 0.42831704, 0.2284312 ],\n",
              "       [0.18672858, 0.15642028, 0.42837802, 0.22847304],\n",
              "       [0.18675274, 0.15646635, 0.4283436 , 0.22843733],\n",
              "       [0.18668884, 0.15632394, 0.42845073, 0.22853647],\n",
              "       [0.18665248, 0.15643603, 0.42846245, 0.22844908],\n",
              "       [0.18667027, 0.15640457, 0.4284485 , 0.22847661],\n",
              "       [0.18671109, 0.1563982 , 0.42839894, 0.22849183],\n",
              "       [0.18674944, 0.15637265, 0.42837355, 0.22850429],\n",
              "       [0.18681328, 0.15647651, 0.4282558 , 0.22845447],\n",
              "       [0.18671656, 0.15634993, 0.4283984 , 0.2285351 ],\n",
              "       [0.18673697, 0.15643258, 0.42836368, 0.2284667 ],\n",
              "       [0.18673605, 0.15634394, 0.42837873, 0.2285413 ],\n",
              "       [0.18670331, 0.15639175, 0.42840943, 0.2284954 ],\n",
              "       [0.18674259, 0.1564247 , 0.42835256, 0.22848013],\n",
              "       [0.18665427, 0.15642418, 0.42845902, 0.22846256],\n",
              "       [0.18671465, 0.1564419 , 0.4283943 , 0.22844917],\n",
              "       [0.18669961, 0.15639207, 0.4284084 , 0.22849993],\n",
              "       [0.18672521, 0.15639198, 0.42839324, 0.2284895 ],\n",
              "       [0.18667008, 0.15634356, 0.4284588 , 0.22852762],\n",
              "       [0.18673949, 0.15641744, 0.42836052, 0.22848251],\n",
              "       [0.18672733, 0.15648468, 0.42835706, 0.22843091],\n",
              "       [0.1867153 , 0.1564924 , 0.42836493, 0.22842735],\n",
              "       [0.18669495, 0.15644395, 0.4283927 , 0.22846834],\n",
              "       [0.18673748, 0.15642895, 0.42836696, 0.22846663],\n",
              "       [0.18674791, 0.15646023, 0.42835492, 0.22843699],\n",
              "       [0.18670312, 0.15646608, 0.42840856, 0.22842227],\n",
              "       [0.18669939, 0.15647133, 0.42838144, 0.22844787],\n",
              "       [0.18673658, 0.15645708, 0.42835107, 0.22845535],\n",
              "       [0.18669371, 0.15641242, 0.4284124 , 0.22848143],\n",
              "       [0.18681464, 0.15640637, 0.4282855 , 0.22849344],\n",
              "       [0.18671791, 0.1563953 , 0.42840865, 0.2284782 ],\n",
              "       [0.18669897, 0.15648054, 0.4283923 , 0.22842827],\n",
              "       [0.18672325, 0.15647629, 0.4283696 , 0.22843082],\n",
              "       [0.18671316, 0.15644652, 0.42836812, 0.22847216],\n",
              "       [0.18675728, 0.15640345, 0.42834228, 0.22849701],\n",
              "       [0.18673621, 0.15638904, 0.4283683 , 0.22850636],\n",
              "       [0.18669401, 0.15635031, 0.42844126, 0.22851445],\n",
              "       [0.18677908, 0.15626454, 0.4283463 , 0.22861005],\n",
              "       [0.18672986, 0.15619455, 0.4284097 , 0.22866584],\n",
              "       [0.18675953, 0.1563274 , 0.4283622 , 0.22855094],\n",
              "       [0.18673113, 0.15643524, 0.42836305, 0.22847055],\n",
              "       [0.18668541, 0.15638766, 0.42843157, 0.22849542],\n",
              "       [0.18675345, 0.15631525, 0.42837322, 0.2285581 ],\n",
              "       [0.18672596, 0.15632288, 0.42839906, 0.22855213],\n",
              "       [0.18669677, 0.15634379, 0.42842138, 0.22853804],\n",
              "       [0.18676719, 0.15642323, 0.42831454, 0.22849505],\n",
              "       [0.18669584, 0.1564711 , 0.42840177, 0.2284313 ],\n",
              "       [0.18673943, 0.15644766, 0.42834625, 0.22846659],\n",
              "       [0.18676502, 0.15645826, 0.42830944, 0.22846732],\n",
              "       [0.18675403, 0.15640397, 0.42834705, 0.22849499],\n",
              "       [0.18677472, 0.15643983, 0.42830276, 0.22848266],\n",
              "       [0.18673389, 0.15634677, 0.42837766, 0.22854164],\n",
              "       [0.18676461, 0.15641238, 0.42832342, 0.22849955],\n",
              "       [0.18674724, 0.15632616, 0.42837298, 0.22855364],\n",
              "       [0.18674643, 0.15639964, 0.42835614, 0.22849777],\n",
              "       [0.18672293, 0.15631951, 0.42840645, 0.22855102],\n",
              "       [0.18676247, 0.15633063, 0.42834857, 0.22855832],\n",
              "       [0.18682534, 0.15644738, 0.42828318, 0.22844408],\n",
              "       [0.18674107, 0.1564106 , 0.42837688, 0.22847146]], dtype=float32)"
            ]
          },
          "execution_count": 77,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(next(train_data_gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "v2Vvsue5Pckw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}